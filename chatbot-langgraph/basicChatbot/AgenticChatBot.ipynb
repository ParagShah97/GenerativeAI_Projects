{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9d2aa7a",
   "metadata": {},
   "source": [
    "#### Tool Binding with LLMs \n",
    "We will bind the tool for giving more functionality to the LLM. Tool (Tool Node) can be anything like vectorDB. SQLDB or Tavily.\n",
    "\n",
    "{Start} -> [Chatbot] -> [ToolNode] -> {END}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e45979cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages    # Reducer to append the previous communication back to State.\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df99a476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4e815ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=openai_api_key,\n",
    "    temperature=0.2,\n",
    "    streaming=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999180ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is langgraph',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'url': 'https://www.datacamp.com/tutorial/langgraph-tutorial',\n",
       "   'title': 'LangGraph Tutorial: What Is LangGraph and How to Use It?',\n",
       "   'content': 'LangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner. By managing the flow of data and the sequence of operations, LangGraph allows developers to focus on the high-level logic of their applications rather than the intricacies of agent coordination. Whether you need a chatbot that can handle various types of user requests or a multi-agent system that performs complex tasks, LangGraph provides the tools to build exactly what you need. LangGraph significantly simplifies the development of complex LLM applications by providing a structured framework for managing state and coordinating agent interactions.',\n",
       "   'score': 0.9502313,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.geeksforgeeks.org/machine-learning/what-is-langgraph/',\n",
       "   'title': 'What is LangGraph? - GeeksforGeeks',\n",
       "   'content': 'LangGraph is an open-source framework built by LangChain that streamlines the creation and management of AI agent workflows.',\n",
       "   'score': 0.9464435,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 0.71,\n",
       " 'request_id': '465a16df-adad-49b0-b821-3d7beb37215d'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "tool=TavilySearch(max_results=2)\n",
    "# tool.invoke(\"What is langgraph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e352734",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Custom function\n",
    "def multiply(a:int,b:int)->int:\n",
    "    \"\"\"Multiply a and b\n",
    "\n",
    "    Args:\n",
    "        a (int): first int\n",
    "        b (int): second int\n",
    "\n",
    "    Returns:\n",
    "        int: output int\n",
    "    \"\"\"\n",
    "    return a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a437a7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[tool,multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77a65a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000002B7A05D8B30>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002B7A0AB5670>, root_client=<openai.OpenAI object at 0x000002B79F16D070>, root_async_client=<openai.AsyncOpenAI object at 0x000002B7A065F320>, model_name='gpt-4o-mini', temperature=0.2, model_kwargs={}, openai_api_key=SecretStr('**********'), streaming=True), kwargs={'tools': [{'type': 'function', 'function': {'name': 'tavily_search', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. It not only retrieves URLs and snippets, but offers advanced search depths, domain management, time range filters, and image search, this tool delivers real-time, accurate, and citation-backed results.Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'Search query to look up', 'type': 'string'}, 'include_domains': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'}, {'type': 'null'}], 'default': [], 'description': 'A list of domains to restrict search results to.\\n\\n        Use this parameter when:\\n        1. The user explicitly requests information from specific websites (e.g., \"Find climate data from nasa.gov\")\\n        2. The user mentions an organization or company without specifying the domain (e.g., \"Find information about iPhones from Apple\")\\n\\n        In both cases, you should determine the appropriate domains (e.g., [\"nasa.gov\"] or [\"apple.com\"]) and set this parameter.\\n\\n        Results will ONLY come from the specified domains - no other sources will be included.\\n        Default is None (no domain restriction).\\n        '}, 'exclude_domains': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'}, {'type': 'null'}], 'default': [], 'description': 'A list of domains to exclude from search results.\\n\\n        Use this parameter when:\\n        1. The user explicitly requests to avoid certain websites (e.g., \"Find information about climate change but not from twitter.com\")\\n        2. The user mentions not wanting results from specific organizations without naming the domain (e.g., \"Find phone reviews but nothing from Apple\")\\n\\n        In both cases, you should determine the appropriate domains to exclude (e.g., [\"twitter.com\"] or [\"apple.com\"]) and set this parameter.\\n\\n        Results will filter out all content from the specified domains.\\n        Default is None (no domain exclusion).\\n        '}, 'search_depth': {'anyOf': [{'enum': ['basic', 'advanced'], 'type': 'string'}, {'type': 'null'}], 'default': 'basic', 'description': 'Controls search thoroughness and result comprehensiveness.\\n    \\n        Use \"basic\" for simple queries requiring quick, straightforward answers.\\n        \\n        Use \"advanced\" (default) for complex queries, specialized topics, \\n        rare information, or when in-depth analysis is needed.\\n        '}, 'include_images': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}], 'default': False, 'description': 'Determines if the search returns relevant images along with text results.\\n   \\n        Set to True when the user explicitly requests visuals or when images would \\n        significantly enhance understanding (e.g., \"Show me what black holes look like,\" \\n        \"Find pictures of Renaissance art\").\\n        \\n        Leave as False (default) for most informational queries where text is sufficient.\\n        '}, 'time_range': {'anyOf': [{'enum': ['day', 'week', 'month', 'year'], 'type': 'string'}, {'type': 'null'}], 'default': None, 'description': 'Limits results to content published within a specific timeframe.\\n        \\n        ONLY set this when the user explicitly mentions a time period \\n        (e.g., \"latest AI news,\" \"articles from last week\").\\n        \\n        For less popular or niche topics, use broader time ranges \\n        (\"month\" or \"year\") to ensure sufficient relevant results.\\n   \\n        Options: \"day\" (24h), \"week\" (7d), \"month\" (30d), \"year\" (365d).\\n        \\n        Default is None.\\n        '}, 'topic': {'anyOf': [{'enum': ['general', 'news', 'finance'], 'type': 'string'}, {'type': 'null'}], 'default': 'general', 'description': 'Specifies search category for optimized results.\\n   \\n        Use \"general\" (default) for most queries, INCLUDING those with terms like \\n        \"latest,\" \"newest,\" or \"recent\" when referring to general information.\\n\\n        Use \"finance\" for markets, investments, economic data, or financial news.\\n\\n        Use \"news\" ONLY for politics, sports, or major current events covered by \\n        mainstream media - NOT simply because a query asks for \"new\" information.\\n        '}, 'include_favicon': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}], 'default': False, 'description': \"Determines whether to include favicon URLs for each search result.\\n        \\n        When enabled, each search result will include the website's favicon URL,\\n        which can be useful for:\\n        - Building rich UI interfaces with visual website indicators\\n        - Providing visual cues about the source's credibility or brand\\n        - Creating bookmark-like displays with recognizable site icons\\n        \\n        Set to True when creating user interfaces that benefit from visual branding\\n        or when favicon information enhances the user experience.\\n        \\n        Default is False to minimize response size and API usage.\\n        \"}, 'start_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'description': 'Filters search results to include only content published on or after this date.\\n        \\n        Use this parameter when you need to:\\n        - Find recent developments or updates on a topic\\n        - Exclude outdated information from search results\\n        - Focus on content within a specific timeframe\\n        - Combine with end_date to create a custom date range\\n        \\n        Format must be YYYY-MM-DD (e.g., \"2024-01-15\" for January 15, 2024).\\n        \\n        Examples:\\n        - \"2024-01-01\" - Results from January 1, 2024 onwards\\n        - \"2023-12-25\" - Results from December 25, 2023 onwards\\n        \\n        When combined with end_date, creates a precise date range filter.\\n        \\n        Default is None (no start date restriction).\\n        '}, 'end_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'description': 'Filters search results to include only content published on or before this date.\\n        \\n        Use this parameter when you need to:\\n        - Exclude content published after a certain date\\n        - Study historical information or past events\\n        - Research how topics were covered during specific time periods\\n        - Combine with start_date to create a custom date range\\n        \\n        Format must be YYYY-MM-DD (e.g., \"2024-03-31\" for March 31, 2024).\\n        \\n        Examples:\\n        - \"2024-03-31\" - Results up to and including March 31, 2024\\n        - \"2023-12-31\" - Results up to and including December 31, 2023\\n        \\n        When combined with start_date, creates a precise date range filter.\\n        For example: start_date=\"2024-01-01\", end_date=\"2024-03-31\" \\n        returns results from Q1 2024 only.\\n        \\n        Default is None (no end date restriction).\\n        '}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'multiply', 'description': 'Multiply a and b', 'parameters': {'properties': {'a': {'description': 'first int', 'type': 'integer'}, 'b': {'description': 'second int', 'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}}}]}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bind LLM with the tools created\n",
    "llm_with_tool=llm.bind_tools(tools)\n",
    "llm_with_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acb5261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Node definition\n",
    "def tool_calling_llm(state:State)->State:\n",
    "    return {\"messages\":[llm_with_tool.invoke(state[\"messages\"])]}\n",
    "\n",
    "## Grpah\n",
    "builder=StateGraph(State)\n",
    "builder.add_node(\"tool_calling_llm\",tool_calling_llm)\n",
    "builder.add_node(\"tools\",ToolNode(tools))\n",
    "\n",
    "## Add Edges\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_conditional_edges(\n",
    "    \"tool_calling_llm\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    "    {\"tools\": \"tools\", END: END},\n",
    ")\n",
    "builder.add_edge(\"tools\",END)\n",
    "\n",
    "## compile the graph\n",
    "graph=builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8784a6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to reach https://mermaid.ink/ API while trying to render your graph. Status code: 502.\n",
      "\n",
      "To resolve this issue:\n",
      "1. Check your internet connection and try again\n",
      "2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n",
      "3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image,display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(e) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e9d2b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = graph.invoke({'messages': \"What is 5 * 5\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39955aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'25'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51b4311f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is 5 * 5\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_qtYjVPYRtzjThxvQT7g03cXq)\n",
      " Call ID: call_qtYjVPYRtzjThxvQT7g03cXq\n",
      "  Args:\n",
      "    a: 5\n",
      "    b: 5\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "for m in response['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34412559",
   "metadata": {},
   "source": [
    "### ReAct Agent Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a9acba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Node definition\n",
    "def tool_calling_llm(state:State)->State:\n",
    "    return {\"messages\":[llm_with_tool.invoke(state[\"messages\"])]}\n",
    "\n",
    "## Grpah\n",
    "reAct_builder=StateGraph(State)\n",
    "reAct_builder.add_node(\"tool_calling_llm\",tool_calling_llm)\n",
    "reAct_builder.add_node(\"tools\",ToolNode(tools))\n",
    "\n",
    "## Add Edges\n",
    "reAct_builder.add_edge(START, \"tool_calling_llm\")\n",
    "reAct_builder.add_conditional_edges(\n",
    "    \"tool_calling_llm\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    "    {\"tools\": \"tools\", END: END},\n",
    ")\n",
    "reAct_builder.add_edge(\"tools\",\"tool_calling_llm\")\n",
    "\n",
    "## compile the graph\n",
    "graph_reAct=reAct_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "854c843c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to reach https://mermaid.ink/ API while trying to render your graph. Status code: 502.\n",
      "\n",
      "To resolve this issue:\n",
      "1. Check your internet connection and try again\n",
      "2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n",
      "3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image,display\n",
    "\n",
    "try:\n",
    "    display(Image(graph_reAct.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(e) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6db4d511",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = graph_reAct.invoke({'messages': \"Give me 5 point news on AI and what is 5*321\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "417713b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Give me 5 point news on AI and what is 5*321\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (call_GPpe1rEv10GbPqWlhgqHZ2UO)\n",
      " Call ID: call_GPpe1rEv10GbPqWlhgqHZ2UO\n",
      "  Args:\n",
      "    query: latest news on AI\n",
      "    search_depth: advanced\n",
      "    topic: news\n",
      "  multiply (call_Vqjw4MBcZi55DHOKthYiKu4H)\n",
      " Call ID: call_Vqjw4MBcZi55DHOKthYiKu4H\n",
      "  Args:\n",
      "    a: 5\n",
      "    b: 321\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"latest news on AI\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://punchng.com/leveraging-ai-to-solve-everyday-challenges/?utm_source=auto-read-also&utm_medium=web\", \"title\": \"Leveraging AI to solve everyday challenges - Punch Newspapers\", \"score\": 0.7986339330673218, \"published_date\": \"Tue, 16 Sep 2025 01:15:29 GMT\", \"content\": \"* Tuesday, September 16, 2025 # Leveraging AI to solve everyday challenges 16th September 2025 In Nigeria, AI is increasingly becoming a practical tool for solving everyday problems, streamlining processes, and driving innovation across multiple sectors. Banks, fintech companies, and payment platforms are leveraging AI to improve operational efficiency, reduce fraud, and enhance customer experience. AI also powers personalised banking solutions for everyday Nigerians. Online courses, simulations, and practical exercises leverage AI to provide real-time feedback, track progress, and recommend next steps for learners. Harnessing AI in everyday life in Nigeria is not simply about adopting new technologies; it is about creating a mindset of awareness, critical engagement, and ethical use. AI has the potential to tackle critical economic, social, and environmental challenges. 16th September 2025\", \"raw_content\": null}, {\"url\": \"https://www.csoonline.com/article/4054301/cisos-grapple-with-the-realities-of-applying-ai-to-security-functions.html\", \"title\": \"CISOs grapple with the realities of applying AI to security functions - csoonline.com\", \"score\": 0.7971751093864441, \"published_date\": \"Tue, 16 Sep 2025 07:02:45 GMT\", \"content\": \"While automation has helped reduce breach identification and response times through rule-based security orchestration, automation and response (SOAR) and endpoint detection and response (EDR) tools, agentic AI technologies offer the potential to turbo boost performance and results. “We’re not seeing AI detection quite there yet, and it’s dangerous because we could be getting lulled into a false sense of security,” says IEEE senior member Shaila Rana. Denida Grow, managing partner at boutique security consultancy LeMareschal, says her experiments suggest AI-based security tooling is still in its early stages of development. “At this point, we cannot base security operations solely on AI-generated reports or recommendations,” Grow says. ### CSO Executive Sessions: How AI and LLMs are affecting security in the financial services industry\", \"raw_content\": null}], \"response_time\": 1.74, \"request_id\": \"8121b5a9-4267-41f5-b2ce-a1235b32bf09\"}\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "1605\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "### Latest News on AI\n",
      "\n",
      "1. **Leveraging AI to Solve Everyday Challenges**  \n",
      "   In Nigeria, AI is becoming a practical tool for addressing everyday problems, enhancing operational efficiency in banks and fintech companies, and improving customer experiences. The focus is on creating a mindset for ethical use and critical engagement with AI technologies.  \n",
      "   [Read more here](https://punchng.com/leveraging-ai-to-solve-everyday-challenges/?utm_source=auto-read-also&utm_medium=web) (Published on September 16, 2025)\n",
      "\n",
      "2. **CISOs Grapple with AI in Security Functions**  \n",
      "   Chief Information Security Officers (CISOs) are facing challenges in applying AI to security functions. While automation has improved breach response times, experts caution that AI detection is still developing, and reliance solely on AI-generated reports can be risky.  \n",
      "   [Read more here](https://www.csoonline.com/article/4054301/cisos-grapple-with-the-realities-of-applying-ai-to-security-functions.html) (Published on September 16, 2025)\n",
      "\n",
      "### Calculation Result\n",
      "The result of \\( 5 \\times 321 \\) is **1605**.\n"
     ]
    }
   ],
   "source": [
    "for m in response['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1c8cd2",
   "metadata": {},
   "source": [
    "### Agent with in Memory\n",
    "This will give the context to the LLM with the help of previous checkpoints. In Memeory is defaultdict which store in form of a thread. Each thread will have stored memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8521b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver # this will store the memory in threads\n",
    "\n",
    "# It will store the checkpoint storage.\n",
    "memory = MemorySaver()\n",
    "\n",
    "## Node definition\n",
    "def tool_calling_llm(state:State)->State:\n",
    "    return {\"messages\":[llm_with_tool.invoke(state[\"messages\"])]}\n",
    "\n",
    "## Grpah\n",
    "reAct_builder_memory=StateGraph(State)\n",
    "reAct_builder_memory.add_node(\"tool_calling_llm\",tool_calling_llm)\n",
    "reAct_builder_memory.add_node(\"tools\",ToolNode(tools))\n",
    "\n",
    "## Add Edges\n",
    "reAct_builder_memory.add_edge(START, \"tool_calling_llm\")\n",
    "reAct_builder_memory.add_conditional_edges(\n",
    "    \"tool_calling_llm\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    "    {\"tools\": \"tools\", END: END},\n",
    ")\n",
    "reAct_builder_memory.add_edge(\"tools\",\"tool_calling_llm\")\n",
    "\n",
    "## compile the graph\n",
    "graph_reAct_memory=reAct_builder_memory.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bc923d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='My Name is Parag Shah', additional_kwargs={}, response_metadata={}, id='fe40c32c-d0c7-4924-8ef3-d8f40f14f819'),\n",
       "  AIMessage(content='Hello, Parag Shah! How can I assist you today?', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'service_tier': 'default'}, id='run--4fdc6bd3-13c7-4916-a7df-5f2fded9a29d-0')]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we need to create a thread Id, to store the intermeidate data/ communication.\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "# In actual env we will seperately save the configuration (thread id) in storage or distributed system.\n",
    "response = graph_reAct_memory.invoke({\"messages\": \"My Name is Parag Shah\"}, config=config)\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "688d9244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='My Name is Parag Shah', additional_kwargs={}, response_metadata={}, id='fe40c32c-d0c7-4924-8ef3-d8f40f14f819'),\n",
       "  AIMessage(content='Hello, Parag Shah! How can I assist you today?', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'service_tier': 'default'}, id='run--4fdc6bd3-13c7-4916-a7df-5f2fded9a29d-0'),\n",
       "  HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}, id='0996fc24-6f5a-461c-837f-8c0aeda6e658'),\n",
       "  AIMessage(content='Your name is Parag Shah.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'service_tier': 'default'}, id='run--d5542e62-e72e-4dba-a686-04196b64abdb-0')]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = graph_reAct_memory.invoke({\"messages\": \"What is my name?\"}, config=config)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a8666e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot-langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
